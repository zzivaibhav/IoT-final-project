{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae18b4c",
   "metadata": {},
   "source": [
    "# LoRaWAN Interactive Peer-Messaging Service - Data Analysis\n",
    "## Project P2 - CSCI-4270/6712 Wireless Technologies for IoT\n",
    "\n",
    "This notebook analyzes the performance data collected from the LoRaWAN peer messaging system according to the project requirements:\n",
    "\n",
    "**Key Analysis Areas:**\n",
    "- Roster discovery performance (devices discovered vs expected, response delays)\n",
    "- Command delivery reliability and end-to-end delays  \n",
    "- Message distribution and signal quality (RSSI/SNR analysis)\n",
    "- Energy consumption estimation based on message patterns\n",
    "- Statistical evaluation with confidence intervals\n",
    "\n",
    "**Data Sources:**\n",
    "- `message_log.csv`: All message traffic with RF parameters\n",
    "- `roster_performance.csv`: DISCOVER/ROSTER performance metrics\n",
    "- `command_delivery.csv`: End-to-end command delivery tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60064dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import Required Libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1347b27",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data\n",
    "\n",
    "Load the three CSV files generated by the LoRaWAN application server and perform basic exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files with error handling\n",
    "data_dir = \"data\"\n",
    "files_info = {}\n",
    "\n",
    "try:\n",
    "    # Load message log\n",
    "    message_log = pd.read_csv(os.path.join(data_dir, \"message_log.csv\"))\n",
    "    message_log['timestamp'] = pd.to_datetime(message_log['timestamp'])\n",
    "    files_info['message_log'] = f\"Loaded {len(message_log)} message records\"\n",
    "    \n",
    "    # Load roster performance\n",
    "    roster_perf = pd.read_csv(os.path.join(data_dir, \"roster_performance.csv\"))\n",
    "    roster_perf['timestamp'] = pd.to_datetime(roster_perf['timestamp'])\n",
    "    files_info['roster_performance'] = f\"Loaded {len(roster_perf)} roster records\"\n",
    "    \n",
    "    # Load command delivery\n",
    "    command_delivery = pd.read_csv(os.path.join(data_dir, \"command_delivery.csv\"))\n",
    "    if len(command_delivery) > 0:\n",
    "        command_delivery['timestamp'] = pd.to_datetime(command_delivery['timestamp'])\n",
    "    files_info['command_delivery'] = f\"Loaded {len(command_delivery)} command delivery records\"\n",
    "    \n",
    "    print(\"âœ… Data Loading Summary:\")\n",
    "    for file, info in files_info.items():\n",
    "        print(f\"  {file}: {info}\")\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Error loading data files: {e}\")\n",
    "    print(\"Make sure you have run the server application to generate data files.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Unexpected error: {e}\")\n",
    "\n",
    "# Display basic info about loaded data\n",
    "if 'message_log' in locals():\n",
    "    print(f\"\\nðŸ“Š Data Collection Period:\")\n",
    "    print(f\"  Start: {message_log['timestamp'].min()}\")\n",
    "    print(f\"  End: {message_log['timestamp'].max()}\")\n",
    "    print(f\"  Duration: {message_log['timestamp'].max() - message_log['timestamp'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f963081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data structure and quality\n",
    "if 'message_log' in locals() and len(message_log) > 0:\n",
    "    print(\"ðŸ“‹ MESSAGE LOG STRUCTURE:\")\n",
    "    print(f\"Shape: {message_log.shape}\")\n",
    "    print(f\"Columns: {list(message_log.columns)}\")\n",
    "    print(f\"Data types:\\n{message_log.dtypes}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Unique devices: {message_log['device_id'].nunique()}\")\n",
    "    print(f\"Devices: {sorted(message_log['device_id'].unique())}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Message types:\")\n",
    "    msg_type_counts = message_log['message_type'].value_counts()\n",
    "    for msg_type, count in msg_type_counts.items():\n",
    "        print(f\"  {msg_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nðŸ” Data Quality Check:\")\n",
    "    null_counts = message_log.isnull().sum()\n",
    "    for col, null_count in null_counts.items():\n",
    "        if null_count > 0:\n",
    "            print(f\"  {col}: {null_count} null values ({null_count/len(message_log)*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\nðŸ“„ Sample Records:\")\n",
    "    print(message_log.head(3))\n",
    "    \n",
    "if 'roster_perf' in locals() and len(roster_perf) > 0:\n",
    "    print(f\"\\n\\nðŸ“‹ ROSTER PERFORMANCE STRUCTURE:\")\n",
    "    print(f\"Shape: {roster_perf.shape}\")\n",
    "    print(f\"Average discovery accuracy: {roster_perf['discovery_accuracy'].mean():.3f}\")\n",
    "    print(f\"Average response delay: {roster_perf['response_delay_ms'].mean():.2f} ms\")\n",
    "    \n",
    "if 'command_delivery' in locals():\n",
    "    print(f\"\\n\\nðŸ“‹ COMMAND DELIVERY STRUCTURE:\")\n",
    "    print(f\"Shape: {command_delivery.shape}\")\n",
    "    if len(command_delivery) > 0:\n",
    "        delivered_count = command_delivery['delivered'].sum() if 'delivered' in command_delivery.columns else 0\n",
    "        print(f\"Delivered commands: {delivered_count}/{len(command_delivery)}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No valid data loaded for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df7951",
   "metadata": {},
   "source": [
    "## 2. RSSI Analysis and Signal Quality\n",
    "\n",
    "Analyze RSSI values to understand signal quality and link performance as required by the project evaluation criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSSI Analysis - Statistical measures and visualization\n",
    "if 'message_log' in locals() and len(message_log) > 0:\n",
    "    # Filter out missing RSSI values\n",
    "    rssi_data = message_log.dropna(subset=['rssi'])\n",
    "    \n",
    "    if len(rssi_data) > 0:\n",
    "        print(\"ðŸ”Š RSSI STATISTICAL ANALYSIS:\")\n",
    "        print(f\"Sample size: {len(rssi_data)} measurements\")\n",
    "        \n",
    "        # Descriptive statistics\n",
    "        rssi_stats = rssi_data['rssi'].describe()\n",
    "        print(f\"\\nDescriptive Statistics:\")\n",
    "        print(f\"  Mean: {rssi_stats['mean']:.2f} dBm\")\n",
    "        print(f\"  Median: {rssi_stats['50%']:.2f} dBm\") \n",
    "        print(f\"  Std Dev: {rssi_stats['std']:.2f} dBm\")\n",
    "        print(f\"  Min: {rssi_stats['min']:.2f} dBm\")\n",
    "        print(f\"  Max: {rssi_stats['max']:.2f} dBm\")\n",
    "        \n",
    "        # 95% Confidence Interval for mean RSSI\n",
    "        confidence_level = 0.95\n",
    "        degrees_freedom = len(rssi_data) - 1\n",
    "        sample_mean = rssi_data['rssi'].mean()\n",
    "        sample_standard_error = stats.sem(rssi_data['rssi'])\n",
    "        confidence_interval = stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n",
    "        print(f\"  95% CI for mean: [{confidence_interval[0]:.2f}, {confidence_interval[1]:.2f}] dBm\")\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # RSSI histogram\n",
    "        ax1.hist(rssi_data['rssi'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        ax1.axvline(sample_mean, color='red', linestyle='--', label=f'Mean: {sample_mean:.1f} dBm')\n",
    "        ax1.axvline(rssi_stats['50%'], color='orange', linestyle='--', label=f'Median: {rssi_stats[\"50%\"]:.1f} dBm')\n",
    "        ax1.set_xlabel('RSSI (dBm)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('RSSI Distribution')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # RSSI by message type boxplot\n",
    "        if rssi_data['message_type'].nunique() > 1:\n",
    "            sns.boxplot(data=rssi_data, x='message_type', y='rssi', ax=ax2)\n",
    "            ax2.set_title('RSSI by Message Type')\n",
    "            ax2.set_ylabel('RSSI (dBm)')\n",
    "            ax2.tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Only one message type\\nin dataset', ha='center', va='center', transform=ax2.transAxes)\n",
    "            ax2.set_title('RSSI by Message Type (Insufficient Data)')\n",
    "        \n",
    "        # RSSI by device\n",
    "        if rssi_data['device_id'].nunique() > 1:\n",
    "            device_rssi = rssi_data.groupby('device_id')['rssi'].agg(['mean', 'std', 'count']).reset_index()\n",
    "            device_rssi.plot(x='device_id', y='mean', kind='bar', ax=ax3, color='lightgreen', alpha=0.7)\n",
    "            ax3.set_title('Average RSSI by Device')\n",
    "            ax3.set_ylabel('Average RSSI (dBm)')\n",
    "            ax3.set_xlabel('Device ID')\n",
    "            ax3.tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'Only one device\\nin dataset', ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.set_title('RSSI by Device (Insufficient Data)')\n",
    "        \n",
    "        # RSSI over time\n",
    "        if len(rssi_data) > 1:\n",
    "            rssi_data_sorted = rssi_data.sort_values('timestamp')\n",
    "            ax4.plot(rssi_data_sorted['timestamp'], rssi_data_sorted['rssi'], marker='o', markersize=3, alpha=0.7)\n",
    "            ax4.set_title('RSSI Over Time')\n",
    "            ax4.set_ylabel('RSSI (dBm)')\n",
    "            ax4.set_xlabel('Time')\n",
    "            ax4.tick_params(axis='x', rotation=45)\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'Insufficient data\\nfor time series', ha='center', va='center', transform=ax4.transAxes)\n",
    "            ax4.set_title('RSSI Over Time (Insufficient Data)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸  No RSSI data available for analysis\")\n",
    "else:\n",
    "    print(\"âš ï¸  No message log data available for RSSI analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb4aa9",
   "metadata": {},
   "source": [
    "## 3. Message Type Distribution and Success Rates\n",
    "\n",
    "Analyze the distribution of different message types and their success rates as required for Project P2 evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d08879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message Type Analysis\n",
    "if 'message_log' in locals() and len(message_log) > 0:\n",
    "    print(\"ðŸ“Š MESSAGE TYPE ANALYSIS:\")\n",
    "    \n",
    "    # Message type distribution\n",
    "    msg_types = message_log['message_type'].value_counts()\n",
    "    total_messages = len(message_log)\n",
    "    \n",
    "    print(f\"\\nMessage Distribution ({total_messages} total messages):\")\n",
    "    for msg_type, count in msg_types.items():\n",
    "        percentage = (count / total_messages) * 100\n",
    "        print(f\"  {msg_type}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Success rates by message type\n",
    "    if 'success' in message_log.columns:\n",
    "        success_by_type = message_log.groupby('message_type')['success'].agg(['count', 'sum', 'mean']).round(3)\n",
    "        success_by_type['success_rate'] = (success_by_type['sum'] / success_by_type['count'] * 100).round(1)\n",
    "        \n",
    "        print(f\"\\nSuccess Rates by Message Type:\")\n",
    "        for msg_type in success_by_type.index:\n",
    "            total = success_by_type.loc[msg_type, 'count']\n",
    "            successful = success_by_type.loc[msg_type, 'sum']\n",
    "            rate = success_by_type.loc[msg_type, 'success_rate']\n",
    "            print(f\"  {msg_type}: {successful}/{total} ({rate}%)\")\n",
    "    \n",
    "    # Payload size analysis\n",
    "    if 'payload_size' in message_log.columns:\n",
    "        payload_stats = message_log.groupby('message_type')['payload_size'].agg(['mean', 'std', 'min', 'max']).round(1)\n",
    "        print(f\"\\nPayload Size by Message Type (bytes):\")\n",
    "        for msg_type in payload_stats.index:\n",
    "            stats = payload_stats.loc[msg_type]\n",
    "            print(f\"  {msg_type}: mean={stats['mean']}, std={stats['std']}, range=[{stats['min']}-{stats['max']}]\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Message type pie chart\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(msg_types)))\n",
    "    ax1.pie(msg_types.values, labels=msg_types.index, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax1.set_title('Message Type Distribution')\n",
    "    \n",
    "    # Message frequency over time\n",
    "    if len(message_log) > 1:\n",
    "        message_log_sorted = message_log.sort_values('timestamp')\n",
    "        hourly_counts = message_log_sorted.set_index('timestamp').resample('5T')['message_type'].count()\n",
    "        ax2.plot(hourly_counts.index, hourly_counts.values, marker='o', markersize=4)\n",
    "        ax2.set_title('Message Frequency Over Time (5-min intervals)')\n",
    "        ax2.set_ylabel('Messages per interval')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Insufficient data\\nfor time analysis', ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Message Frequency Over Time')\n",
    "    \n",
    "    # Success rate by message type (if available)\n",
    "    if 'success' in message_log.columns and len(success_by_type) > 0:\n",
    "        success_by_type['success_rate'].plot(kind='bar', ax=ax3, color='lightcoral', alpha=0.7)\n",
    "        ax3.set_title('Success Rate by Message Type')\n",
    "        ax3.set_ylabel('Success Rate (%)')\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        ax3.set_ylim(0, 100)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'Success data\\nnot available', ha='center', va='center', transform=ax3.transAxes)\n",
    "        ax3.set_title('Success Rate by Message Type')\n",
    "    \n",
    "    # Payload size distribution\n",
    "    if 'payload_size' in message_log.columns:\n",
    "        payload_data = message_log.dropna(subset=['payload_size'])\n",
    "        if len(payload_data) > 0:\n",
    "            sns.boxplot(data=payload_data, x='message_type', y='payload_size', ax=ax4)\n",
    "            ax4.set_title('Payload Size Distribution by Message Type')\n",
    "            ax4.set_ylabel('Payload Size (bytes)')\n",
    "            ax4.tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'No payload size\\ndata available', ha='center', va='center', transform=ax4.transAxes)\n",
    "            ax4.set_title('Payload Size Distribution')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'Payload size\\ndata not available', ha='center', va='center', transform=ax4.transAxes)\n",
    "        ax4.set_title('Payload Size Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸  No message log data available for message type analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2984a42",
   "metadata": {},
   "source": [
    "## 4. Roster Discovery Performance\n",
    "\n",
    "Analyze DISCOVER/ROSTER functionality performance including discovery accuracy and response delays as required by Project P2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roster Discovery Performance Analysis\n",
    "if 'roster_perf' in locals() and len(roster_perf) > 0:\n",
    "    print(\"ðŸŽ¯ ROSTER DISCOVERY PERFORMANCE:\")\n",
    "    print(f\"Total discovery attempts: {len(roster_perf)}\")\n",
    "    \n",
    "    # Discovery accuracy statistics\n",
    "    accuracy_stats = roster_perf['discovery_accuracy'].describe()\n",
    "    print(f\"\\nDiscovery Accuracy Statistics:\")\n",
    "    print(f\"  Mean: {accuracy_stats['mean']:.3f} ({accuracy_stats['mean']*100:.1f}%)\")\n",
    "    print(f\"  Median: {accuracy_stats['50%']:.3f} ({accuracy_stats['50%']*100:.1f}%)\")\n",
    "    print(f\"  Std Dev: {accuracy_stats['std']:.3f}\")\n",
    "    print(f\"  Min: {accuracy_stats['min']:.3f} ({accuracy_stats['min']*100:.1f}%)\")\n",
    "    print(f\"  Max: {accuracy_stats['max']:.3f} ({accuracy_stats['max']*100:.1f}%)\")\n",
    "    \n",
    "    # 95% CI for discovery accuracy\n",
    "    if len(roster_perf) > 1:\n",
    "        accuracy_ci = stats.t.interval(0.95, len(roster_perf)-1, \n",
    "                                     roster_perf['discovery_accuracy'].mean(),\n",
    "                                     stats.sem(roster_perf['discovery_accuracy']))\n",
    "        print(f\"  95% CI: [{accuracy_ci[0]:.3f}, {accuracy_ci[1]:.3f}] ({accuracy_ci[0]*100:.1f}% - {accuracy_ci[1]*100:.1f}%)\")\n",
    "    \n",
    "    # Response delay statistics\n",
    "    if 'response_delay_ms' in roster_perf.columns:\n",
    "        delay_data = roster_perf.dropna(subset=['response_delay_ms'])\n",
    "        if len(delay_data) > 0:\n",
    "            delay_stats = delay_data['response_delay_ms'].describe()\n",
    "            print(f\"\\nResponse Delay Statistics (ms):\")\n",
    "            print(f\"  Mean: {delay_stats['mean']:.2f} ms\")\n",
    "            print(f\"  Median: {delay_stats['50%']:.2f} ms\")\n",
    "            print(f\"  Std Dev: {delay_stats['std']:.2f} ms\")\n",
    "            print(f\"  Min: {delay_stats['min']:.2f} ms\")\n",
    "            print(f\"  Max: {delay_stats['max']:.2f} ms\")\n",
    "            \n",
    "            # 95% CI for response delay\n",
    "            if len(delay_data) > 1:\n",
    "                delay_ci = stats.t.interval(0.95, len(delay_data)-1,\n",
    "                                          delay_data['response_delay_ms'].mean(),\n",
    "                                          stats.sem(delay_data['response_delay_ms']))\n",
    "                print(f\"  95% CI: [{delay_ci[0]:.2f}, {delay_ci[1]:.2f}] ms\")\n",
    "    \n",
    "    # Devices discovered vs expected analysis\n",
    "    print(f\"\\nDevice Discovery Analysis:\")\n",
    "    total_discovered = roster_perf['devices_discovered'].sum()\n",
    "    total_expected = roster_perf['devices_expected'].sum()\n",
    "    print(f\"  Total devices discovered: {total_discovered}\")\n",
    "    print(f\"  Total devices expected: {total_expected}\")\n",
    "    if total_expected > 0:\n",
    "        overall_accuracy = total_discovered / total_expected\n",
    "        print(f\"  Overall discovery rate: {overall_accuracy:.3f} ({overall_accuracy*100:.1f}%)\")\n",
    "    \n",
    "    # False negatives analysis\n",
    "    if total_expected > 0:\n",
    "        false_negatives = total_expected - total_discovered\n",
    "        false_negative_rate = false_negatives / total_expected\n",
    "        print(f\"  False negatives: {false_negatives} ({false_negative_rate*100:.1f}%)\")\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Discovery accuracy histogram\n",
    "    ax1.hist(roster_perf['discovery_accuracy'], bins=10, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "    ax1.axvline(roster_perf['discovery_accuracy'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {roster_perf[\"discovery_accuracy\"].mean():.3f}')\n",
    "    ax1.set_xlabel('Discovery Accuracy')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Discovery Accuracy Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Response delay histogram\n",
    "    if 'response_delay_ms' in roster_perf.columns:\n",
    "        delay_data = roster_perf.dropna(subset=['response_delay_ms'])\n",
    "        if len(delay_data) > 0:\n",
    "            ax2.hist(delay_data['response_delay_ms'], bins=10, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "            ax2.axvline(delay_data['response_delay_ms'].mean(), color='red', linestyle='--',\n",
    "                       label=f'Mean: {delay_data[\"response_delay_ms\"].mean():.1f} ms')\n",
    "            ax2.set_xlabel('Response Delay (ms)')\n",
    "            ax2.set_ylabel('Frequency')\n",
    "            ax2.set_title('Response Delay Distribution')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'No delay data\\navailable', ha='center', va='center', transform=ax2.transAxes)\n",
    "            ax2.set_title('Response Delay Distribution')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Delay data\\nnot available', ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Response Delay Distribution')\n",
    "    \n",
    "    # Devices discovered vs expected scatter plot\n",
    "    ax3.scatter(roster_perf['devices_expected'], roster_perf['devices_discovered'], alpha=0.7, color='orange')\n",
    "    max_devices = max(roster_perf['devices_expected'].max(), roster_perf['devices_discovered'].max())\n",
    "    ax3.plot([0, max_devices], [0, max_devices], 'r--', label='Perfect Discovery')\n",
    "    ax3.set_xlabel('Devices Expected')\n",
    "    ax3.set_ylabel('Devices Discovered')\n",
    "    ax3.set_title('Discovery Performance: Expected vs Discovered')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Discovery accuracy over time\n",
    "    if len(roster_perf) > 1:\n",
    "        roster_sorted = roster_perf.sort_values('timestamp')\n",
    "        ax4.plot(roster_sorted['timestamp'], roster_sorted['discovery_accuracy'], marker='o', markersize=4)\n",
    "        ax4.set_xlabel('Time')\n",
    "        ax4.set_ylabel('Discovery Accuracy')\n",
    "        ax4.set_title('Discovery Accuracy Over Time')\n",
    "        ax4.tick_params(axis='x', rotation=45)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.set_ylim(0, 1.1)\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'Insufficient data\\nfor time series', ha='center', va='center', transform=ax4.transAxes)\n",
    "        ax4.set_title('Discovery Accuracy Over Time')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "elif 'roster_perf' in locals():\n",
    "    print(\"âš ï¸  Roster performance data loaded but empty\")\n",
    "else:\n",
    "    print(\"âš ï¸  No roster performance data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15498dc",
   "metadata": {},
   "source": [
    "## 5. End-to-End Delay Analysis\n",
    "\n",
    "Analyze command delivery delays from COMMAND to ACK as required by Project P2 evaluation criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a528e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-End Delay Analysis\n",
    "if 'command_delivery' in locals() and len(command_delivery) > 0:\n",
    "    print(\"â±ï¸  END-TO-END DELAY ANALYSIS:\")\n",
    "    print(f\"Total command delivery records: {len(command_delivery)}\")\n",
    "    \n",
    "    # Filter records with delivery delay data\n",
    "    delay_data = command_delivery.dropna(subset=['delivery_delay_ms'])\n",
    "    \n",
    "    if len(delay_data) > 0:\n",
    "        print(f\"Records with delay measurements: {len(delay_data)}\")\n",
    "        \n",
    "        # Delay statistics\n",
    "        delay_stats = delay_data['delivery_delay_ms'].describe()\n",
    "        print(f\"\\nDelivery Delay Statistics (ms):\")\n",
    "        print(f\"  Mean: {delay_stats['mean']:.2f} ms\")\n",
    "        print(f\"  Median: {delay_stats['50%']:.2f} ms\")\n",
    "        print(f\"  Std Dev: {delay_stats['std']:.2f} ms\")\n",
    "        print(f\"  Min: {delay_stats['min']:.2f} ms\")\n",
    "        print(f\"  Max: {delay_stats['max']:.2f} ms\")\n",
    "        print(f\"  25th percentile: {delay_stats['25%']:.2f} ms\")\n",
    "        print(f\"  75th percentile: {delay_stats['75%']:.2f} ms\")\n",
    "        \n",
    "        # 95% Confidence Interval for mean delay\n",
    "        if len(delay_data) > 1:\n",
    "            delay_ci = stats.t.interval(0.95, len(delay_data)-1,\n",
    "                                      delay_data['delivery_delay_ms'].mean(),\n",
    "                                      stats.sem(delay_data['delivery_delay_ms']))\n",
    "            print(f\"  95% CI for mean: [{delay_ci[0]:.2f}, {delay_ci[1]:.2f}] ms\")\n",
    "        \n",
    "        # Convert to seconds for better understanding\n",
    "        print(f\"\\nDelay in Seconds:\")\n",
    "        print(f\"  Mean: {delay_stats['mean']/1000:.3f} seconds\")\n",
    "        print(f\"  Median: {delay_stats['50%']/1000:.3f} seconds\")\n",
    "        print(f\"  Max: {delay_stats['max']/1000:.3f} seconds\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸  No delay measurements available in command delivery data\")\n",
    "    \n",
    "    # Delivery success analysis\n",
    "    if 'delivered' in command_delivery.columns:\n",
    "        delivered_count = command_delivery['delivered'].sum()\n",
    "        total_commands = len(command_delivery)\n",
    "        delivery_rate = delivered_count / total_commands if total_commands > 0 else 0\n",
    "        \n",
    "        print(f\"\\nDelivery Success Analysis:\")\n",
    "        print(f\"  Commands sent: {total_commands}\")\n",
    "        print(f\"  Commands delivered: {delivered_count}\")\n",
    "        print(f\"  Delivery rate: {delivery_rate:.3f} ({delivery_rate*100:.1f}%)\")\n",
    "        \n",
    "        # Failed deliveries\n",
    "        failed_count = total_commands - delivered_count\n",
    "        print(f\"  Failed deliveries: {failed_count} ({(failed_count/total_commands)*100:.1f}%)\")\n",
    "    \n",
    "    # ACK analysis\n",
    "    if 'ack_received' in command_delivery.columns:\n",
    "        ack_count = command_delivery['ack_received'].sum()\n",
    "        ack_rate = ack_count / len(command_delivery) if len(command_delivery) > 0 else 0\n",
    "        \n",
    "        print(f\"\\nACK Analysis:\")\n",
    "        print(f\"  ACKs received: {ack_count}\")\n",
    "        print(f\"  ACK rate: {ack_rate:.3f} ({ack_rate*100:.1f}%)\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    if len(delay_data) > 0:\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Delay histogram\n",
    "        ax1.hist(delay_data['delivery_delay_ms'], bins=15, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "        ax1.axvline(delay_data['delivery_delay_ms'].mean(), color='red', linestyle='--',\n",
    "                   label=f'Mean: {delay_data[\"delivery_delay_ms\"].mean():.1f} ms')\n",
    "        ax1.axvline(delay_data['delivery_delay_ms'].median(), color='orange', linestyle='--',\n",
    "                   label=f'Median: {delay_data[\"delivery_delay_ms\"].median():.1f} ms')\n",
    "        ax1.set_xlabel('Delivery Delay (ms)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('End-to-End Delay Distribution')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Delay box plot\n",
    "        ax2.boxplot(delay_data['delivery_delay_ms'])\n",
    "        ax2.set_ylabel('Delivery Delay (ms)')\n",
    "        ax2.set_title('Delay Distribution (Box Plot)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Delay over time\n",
    "        if len(delay_data) > 1:\n",
    "            delay_sorted = delay_data.sort_values('timestamp')\n",
    "            ax3.plot(delay_sorted['timestamp'], delay_sorted['delivery_delay_ms'], \n",
    "                    marker='o', markersize=4, alpha=0.7)\n",
    "            ax3.set_xlabel('Time')\n",
    "            ax3.set_ylabel('Delivery Delay (ms)')\n",
    "            ax3.set_title('Delivery Delay Over Time')\n",
    "            ax3.tick_params(axis='x', rotation=45)\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'Insufficient data\\nfor time series', ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.set_title('Delivery Delay Over Time')\n",
    "        \n",
    "        # Cumulative distribution\n",
    "        sorted_delays = np.sort(delay_data['delivery_delay_ms'])\n",
    "        y_vals = np.arange(1, len(sorted_delays) + 1) / len(sorted_delays)\n",
    "        ax4.plot(sorted_delays, y_vals, marker='o', markersize=3)\n",
    "        ax4.set_xlabel('Delivery Delay (ms)')\n",
    "        ax4.set_ylabel('Cumulative Probability')\n",
    "        ax4.set_title('Cumulative Distribution of Delays')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"ðŸ“Š No delay data available for visualization\")\n",
    "    \n",
    "    # Summary statistics table\n",
    "    if len(delay_data) > 0:\n",
    "        print(\"\\nðŸ“‹ DELAY ANALYSIS SUMMARY TABLE:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"{'Metric':<20} {'Value':<15} {'Unit'}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"{'Sample Size':<20} {len(delay_data):<15} {'measurements'}\")\n",
    "        print(f\"{'Mean Delay':<20} {delay_data['delivery_delay_ms'].mean():.2f}:<15} {'ms'}\")\n",
    "        print(f\"{'Median Delay':<20} {delay_data['delivery_delay_ms'].median():.2f}:<15} {'ms'}\")\n",
    "        print(f\"{'Std Deviation':<20} {delay_data['delivery_delay_ms'].std():.2f}:<15} {'ms'}\")\n",
    "        print(f\"{'Min Delay':<20} {delay_data['delivery_delay_ms'].min():.2f}:<15} {'ms'}\")\n",
    "        print(f\"{'Max Delay':<20} {delay_data['delivery_delay_ms'].max():.2f}:<15} {'ms'}\")\n",
    "        if len(delay_data) > 1:\n",
    "            print(f\"{'95% CI Lower':<20} {delay_ci[0]:.2f}:<15} {'ms'}\")\n",
    "            print(f\"{'95% CI Upper':<20} {delay_ci[1]:.2f}:<15} {'ms'}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "elif 'command_delivery' in locals():\n",
    "    print(\"âš ï¸  Command delivery data loaded but empty\")\n",
    "else:\n",
    "    print(\"âš ï¸  No command delivery data available for delay analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442dc3f0",
   "metadata": {},
   "source": [
    "## 6. Delivery Success Rate and Reliability Analysis\n",
    "\n",
    "Analyze message delivery success rates and identify factors affecting delivery reliability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
